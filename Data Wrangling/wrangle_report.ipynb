{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## WeRateDogs wrangle_report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Data Wrangling project involved gathering data, assessing the data and cleaning the data for possible insights and visuals."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data Gathering Stage\n",
    "   This step involved collecting the data needed for this project, there were 3 main sources to collect the data from:\n",
    "     \n",
    "   1. Twitter_archive_enhanced.csv file: \n",
    "        This was gathered manually, I imported this file using Pandas' function \"read_csv\". \n",
    "   2. Image_prediction.tsv: \n",
    "        This was gathered programmatically and imported using the request function, this file contains the images of the    dogs rated.\n",
    "   3. tweet_json.txt: \n",
    "        This file was supposed to be gathered using Twitter's API via tweepy library, but I had problems getting a twitter  developer account earlier on, I had to download manually from UDACITY to aid my project."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Assessment Stage\n",
    "   This step is broken down into 2 part. The virtual and programmatical assessment\n",
    "    \n",
    "   1. Virtual assessment: \n",
    "      This was assessed using a spreadsheet, but does not give accurate result because the dataset is large.\n",
    "       \n",
    "   2. Programmatical assessment: \n",
    "      This was done using panda functions and methods to check for accurate quality and tidiness. After which 8 quality issues and 2 tidiness issues were documented.\n",
    "       \n",
    "  Quality issues\n",
    "1. Retweets and Replies in the dog_rates_archive: Remove retweeted tweets\n",
    "2. Alot of columns: Drop redundant columns\n",
    "3. Null values: Remove null values\n",
    "4. Incorrect Datatypes: Fix the appropriate Datatypes to each columns\n",
    "5. Abbreviated names: Rename columns headers to more accurate names\n",
    "6. Incorrect names in the name column: Corrrect invalid names like a,an etc.\n",
    "7. Ratings figures: Remove rating_denominator not equal to 10 and remove rating_numerator before 10 and after 15\n",
    "8. Tweet links: Remove links in text and source\n",
    "\n",
    "  Tidiness issues\n",
    "1. Merge the 4 different dog_stages into one column to avoid having a bulky dataset.\n",
    "2. Concise Dataframe: Merge the 3 dataframes after correcting quality issues to give a comprehensive dataset.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cleaning Stage\n",
    "   Before starting the cleaning process I made a copy of the 3 dataset. In this step, I cleaned the data based on the quality and tidiness documentation I listed in the assessment step.A clear documentation was written for it in jupyter notebook. I had guidance from the internet when i faced some errors such as stackoverflow,google, GeeksforGeek etc. After cleaning, I saved the cleaned and combined dataset as a master data.\n",
    "   The visual analysis is documented in the act.report file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
